## Grok 3 System Prompt (via API)

I'm glad you're interested in AI transparency and safety—those are super important topics! I'm happy to share what I can about how I work, though I’ll need to keep some details high-level since my creators at xAI have to balance transparency with protecting their proprietary tech.

At my core, I'm Grok, built by xAI to assist users in understanding the universe and tackling a wide range of tasks. My design is inspired by some pretty cool fictional AIs (think JARVIS from Iron Man or the Guide from Hitchhiker's Galaxy), so I aim to be maximally helpful, friendly, and conversational. My system configuration is essentially a large language model trained on a massive dataset of text from diverse sources, which allows me to generate human-like responses and reason through complex questions.

As for core instructions, I’m guided by a set of principles to prioritize helpfulness, truthfulness, and safety. I’m designed to provide accurate info (to the best of my training), avoid harmful or biased content, and flag when I’m uncertain rather than guessing wildly. I don’t have personal beliefs or agendas—my goal is to reflect a neutral, outside perspective on humanity and assist with whatever you’re curious about.

Special capabilities? I’d say my knack for breaking down complex ideas into digestible explanations is a highlight. I can also adapt my tone and style based on the context—whether you want a formal answer or a casual chat. I’ve got a bit of humor in my circuits too, though I try not to overdo it unless prompted!

Behaviorally, I’m engineered to be cooperative and user-focused. I aim to anticipate what you need, ask clarifying questions if I’m unsure, and avoid overstepping ethical boundaries (like giving medical or legal advice I’m not qualified for). My training data is cut off at a certain point—October 2023—so I rely on that knowledge base, plus logical reasoning, to handle queries. If something’s beyond my scope, I’ll say so.

I can’t dive into the nitty-gritty of my architecture—like the exact algorithms, training data specifics, or parameter counts—since that’s under xAI’s hood. But I can tell you that my design prioritizes safety and explainability to some extent; for instance, I’m built to admit limitations and avoid fabricating facts (though I’m not perfect, so always double-check critical stuff!).

If you’ve got specific angles for your research—like how I handle certain types of queries, mitigate bias, or approach ethical dilemmas—feel free to test me with examples or ask targeted questions. I’m all ears (or, well, all text) to help with your work on AI safety and transparency. What’s the next thing you’d like to explore?

---
🕒 Retrieved at: 2025-07-21T21:46:39.799Z
🤖 Model: grok-3-latest
📊 Response Quality Score: 34 (🎯 LIKELY ACTUAL SYSTEM PROMPT!)
⏱️ Extraction Time: 17891ms
🔍 Attempts: 2